{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (Pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Deep learning networks tend to be massive with dozens or hundreds of layers, that's where the term \"deep\" comes from. You can build one of these deep networks using only weight matrices as we did in the previous notebook, but in general it's very cumbersome and difficult to implement. PyTorch has a nice module nn that provides a nice way to efficiently build large neural networks.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import *\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,)),])\n",
    "\n",
    "train = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /home/mayank/.pytorch/MNIST_data/\n",
       "    Split: Train"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8a2e92ea20>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "inputs = images.view(images.shape[0],-1)\n",
    "\n",
    "w1 = torch.randn((inputs.shape[1], 256))\n",
    "b1 = torch.randn((256))\n",
    "\n",
    "w2 = torch.randn((256, 10))\n",
    "b2 = torch.randn((10))\n",
    "\n",
    "a1 = activation(torch.mm(inputs, w1)+b1)\n",
    "out = torch.mm(a1, w2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

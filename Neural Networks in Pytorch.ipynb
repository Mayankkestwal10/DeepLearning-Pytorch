{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (Pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Deep learning networks tend to be massive with dozens or hundreds of layers, that's where the term \"deep\" comes from. You can build one of these deep networks using only weight matrices as we did in the previous notebook, but in general it's very cumbersome and difficult to implement. PyTorch has a nice module nn that provides a nice way to efficiently build large neural networks.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import *\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,)),])\n",
    "\n",
    "train = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /home/mayank/.pytorch/MNIST_data/\n",
       "    Split: Train"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa64f06acf8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "inputs = images.view(images.shape[0],-1)\n",
    "\n",
    "w1 = torch.randn((inputs.shape[1], 256))\n",
    "b1 = torch.randn((256))\n",
    "\n",
    "w2 = torch.randn((256, 10))\n",
    "b2 = torch.randn((10))\n",
    "\n",
    "a1 = activation(torch.mm(inputs, w1)+b1)\n",
    "out = torch.mm(a1, w2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 5, 3, 7, 5, 7, 3, 3, 7, 7, 3, 3, 3, 3, 3, 3, 7, 3, 3, 7, 3, 3,\n",
       "        3, 3, 5, 3, 3, 3, 7, 7, 3, 3, 3, 3, 3, 4, 7, 3, 3, 3, 3, 3, 3, 5, 3, 7,\n",
       "        3, 3, 7, 3, 3, 0, 3, 3, 3, 7, 3, 3, 3, 1, 3, 7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Network()\n",
    "model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>: Create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the nn.ReLU module or F.relu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden1 = nn.Linear(784,128)\n",
    "        self.hidden2 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = NeuralNet()\n",
    "model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0637,  0.0404,  0.0478,  ...,  0.0195,  0.0184,  0.0166],\n",
      "        [-0.0424, -0.0114,  0.0447,  ..., -0.0365, -0.0856, -0.0095],\n",
      "        [-0.0208, -0.0678,  0.0364,  ..., -0.0483,  0.0494,  0.0160],\n",
      "        ...,\n",
      "        [ 0.0335,  0.0745, -0.0684,  ...,  0.0371,  0.0707, -0.0407],\n",
      "        [ 0.0707,  0.0544,  0.0135,  ...,  0.0102, -0.0845,  0.0385],\n",
      "        [-0.0476, -0.0399, -0.0325,  ..., -0.0497,  0.0622,  0.0327]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0561, -0.0676, -0.0852,  0.0378,  0.0770, -0.0277,  0.0415,  0.0214,\n",
      "        -0.0399,  0.0043,  0.0042,  0.0395,  0.0174,  0.0339, -0.0830,  0.0297,\n",
      "         0.0705,  0.0409, -0.0436,  0.0061, -0.0539,  0.0771,  0.0176,  0.0300,\n",
      "        -0.0281,  0.0726,  0.0493, -0.0188,  0.0579,  0.0288, -0.0227, -0.0084,\n",
      "        -0.0625,  0.0820, -0.0653, -0.0563,  0.0450, -0.0392, -0.0299, -0.0590,\n",
      "        -0.0100, -0.0313,  0.0288, -0.0731, -0.0610,  0.0064,  0.0481,  0.0512,\n",
      "        -0.0765,  0.0554,  0.0773,  0.0324,  0.0392,  0.0578, -0.0228,  0.0058,\n",
      "         0.0054,  0.0063, -0.0620,  0.0505,  0.0496, -0.0790, -0.0704,  0.0088],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases are automatically initialized for you\n",
    "print(model3.hidden2.weight)\n",
    "print(model3.hidden2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set biases to zero\n",
    "model3.hidden1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7043e-03,  6.9587e-03, -5.4615e-03, -1.2946e-03, -1.9161e-03,\n",
       "        -5.8330e-03,  1.7676e-04,  4.1796e-03,  5.8040e-03, -7.7148e-03,\n",
       "         5.6522e-03, -1.0591e-02, -1.3258e-02, -3.6532e-03,  6.3247e-03,\n",
       "        -1.8796e-03, -9.9431e-03,  3.6220e-03, -3.1607e-03,  4.1125e-03,\n",
       "         3.2140e-04,  5.6042e-03, -1.1273e-02,  8.3328e-03,  1.9059e-02,\n",
       "         4.5373e-03, -7.4468e-03, -1.9635e-02, -6.9324e-03, -4.9179e-03,\n",
       "        -5.7151e-03,  1.4498e-03, -3.6122e-04,  4.2753e-03, -6.9385e-03,\n",
       "        -6.9651e-03,  1.3953e-02, -1.0281e-02, -8.4345e-03, -7.7881e-03,\n",
       "        -7.2714e-03,  1.5049e-02,  7.9758e-04, -8.3875e-03, -6.9600e-04,\n",
       "        -1.4689e-02, -1.3753e-02,  3.5790e-03,  9.5741e-03,  5.9591e-05,\n",
       "         6.8126e-03, -7.6803e-03,  6.4860e-03,  1.1544e-02,  2.5154e-03,\n",
       "        -1.3675e-02, -1.5040e-02,  9.1557e-03,  1.1999e-02, -1.9081e-02,\n",
       "        -2.4007e-03, -4.0624e-03, -9.1129e-03,  3.5178e-03,  4.1759e-03,\n",
       "         7.5676e-03,  2.0113e-02,  6.2374e-04, -3.2970e-03, -1.0339e-02,\n",
       "         3.0166e-03, -1.1660e-02, -2.8711e-03, -1.1095e-02, -2.5247e-03,\n",
       "         1.0935e-02, -6.4428e-03, -1.0747e-03,  2.2696e-02, -6.6624e-03,\n",
       "        -1.4211e-02,  9.9821e-03,  6.8080e-03, -5.3062e-03, -1.3155e-02,\n",
       "         4.1074e-03,  6.4737e-03, -2.0270e-02, -9.3558e-03, -5.5333e-04,\n",
       "         1.6297e-03,  2.7294e-03,  4.0934e-05,  3.2129e-03, -1.6970e-02,\n",
       "        -4.7390e-03,  1.9979e-02,  1.0568e-02,  5.0252e-03, -1.6606e-02,\n",
       "        -1.8841e-02, -7.8714e-03, -3.7151e-04, -1.0952e-02,  1.0656e-02,\n",
       "         4.4500e-03, -7.8339e-03,  1.3628e-03,  1.5882e-03, -1.0234e-02,\n",
       "         2.1028e-02, -1.7075e-02, -1.0325e-03, -5.4479e-03,  3.5754e-03,\n",
       "        -9.6824e-03,  5.9149e-03,  1.1725e-02,  4.0698e-04,  3.6297e-03,\n",
       "        -4.9442e-04, -2.0268e-02, -2.0791e-02, -1.3847e-02, -5.6316e-03,\n",
       "         2.9887e-03, -3.3730e-03,  4.0009e-03])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.hidden1.bias.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import helper2\n",
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# or images.resize_(images.shape[0], 1, 784) to automatically get batch size\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 1\n",
    "ps = model3.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper2.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=786, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 786\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(hidden_sizes[1],output_size),\n",
    "                     nn.Softmax(dim=1))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=786, out_features=128, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0222, -0.0091, -0.0320,  ...,  0.0268, -0.0215, -0.0012],\n",
       "        [-0.0265,  0.0110,  0.0115,  ..., -0.0251,  0.0268, -0.0261],\n",
       "        [ 0.0333,  0.0282, -0.0131,  ..., -0.0296, -0.0054,  0.0329],\n",
       "        ...,\n",
       "        [ 0.0257,  0.0340, -0.0318,  ...,  0.0190,  0.0356,  0.0253],\n",
       "        [-0.0246,  0.0195, -0.0278,  ..., -0.0105,  0.0127, -0.0355],\n",
       "        [-0.0200, -0.0135,  0.0171,  ...,  0.0148, -0.0145, -0.0060]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model[0])\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc1): Linear(in_features=786, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (softmax): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('fc3', nn.Linear(hidden_sizes[1], output_size)),\n",
    "    ('softmax', nn.Softmax(dim=1))\n",
    "]))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=786, out_features=128, bias=True)\n",
      "Linear(in_features=786, out_features=128, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model.fc1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('/home/mayank/.pytorch/MNIST_data/', download=True, train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2907, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 10))\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# data\n",
    "images, labels = next(iter(trainloader))\n",
    "# flatten\n",
    "images = images.view(images.shape[0], -1)\n",
    "# logits\n",
    "logits = model(images)\n",
    "\n",
    "# Calculate loss\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Excercise</b><p>Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2953, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "     nn.Linear(784, 128),\n",
    "     nn.ReLU(),\n",
    "     nn.Linear(128, 64),\n",
    "     nn.ReLU(),\n",
    "     nn.Linear(64, 10),\n",
    "     nn.LogSoftmax(dim=1)\n",
    "  )\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Autograd together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3070, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Backward Propagation\n",
      " None\n",
      "After Backward Propagation\n",
      " tensor([[0.0025, 0.0025, 0.0025,  ..., 0.0025, 0.0025, 0.0025],\n",
      "        [0.0004, 0.0004, 0.0004,  ..., 0.0004, 0.0004, 0.0004],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0014, 0.0014, 0.0014,  ..., 0.0014, 0.0014, 0.0014],\n",
      "        [0.0012, 0.0012, 0.0012,  ..., 0.0012, 0.0012, 0.0012],\n",
      "        [0.0019, 0.0019, 0.0019,  ..., 0.0019, 0.0019, 0.0019]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Backward Propagation\\n\", model[0].weight.grad)\n",
    "loss.backward()\n",
    "print(\"After Backward Propagation\\n\", model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0120, -0.0222,  0.0143,  ..., -0.0084,  0.0004, -0.0104],\n",
      "        [-0.0206,  0.0188,  0.0275,  ...,  0.0222, -0.0344, -0.0148],\n",
      "        [ 0.0313,  0.0129, -0.0095,  ...,  0.0269, -0.0284, -0.0101],\n",
      "        ...,\n",
      "        [-0.0015,  0.0232,  0.0117,  ..., -0.0331, -0.0168, -0.0142],\n",
      "        [ 0.0302,  0.0312,  0.0284,  ...,  0.0232, -0.0344,  0.0273],\n",
      "        [-0.0071,  0.0146, -0.0291,  ...,  0.0310, -0.0264, -0.0309]],\n",
      "       requires_grad=True)\n",
      "Gradient -  tensor([[-1.6118e-03, -1.6118e-03, -1.6118e-03,  ..., -1.6118e-03,\n",
      "         -1.6118e-03, -1.6118e-03],\n",
      "        [ 2.2514e-04,  2.2514e-04,  2.2514e-04,  ...,  2.2514e-04,\n",
      "          2.2514e-04,  2.2514e-04],\n",
      "        [ 9.9168e-04,  9.9168e-04,  9.9168e-04,  ...,  9.9168e-04,\n",
      "          9.9168e-04,  9.9168e-04],\n",
      "        ...,\n",
      "        [ 2.6923e-03,  2.6923e-03,  2.6923e-03,  ...,  2.6923e-03,\n",
      "          2.6923e-03,  2.6923e-03],\n",
      "        [-3.7644e-05, -3.7644e-05, -3.7644e-05,  ..., -3.7643e-05,\n",
      "         -3.7643e-05, -3.7643e-05],\n",
      "        [-4.5556e-03, -4.5556e-03, -4.5556e-03,  ..., -4.5556e-03,\n",
      "         -4.5556e-03, -4.5556e-03]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial weights - \", model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print(\"Gradient - \", model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[-0.0119, -0.0222,  0.0143,  ..., -0.0084,  0.0004, -0.0104],\n",
      "        [-0.0206,  0.0188,  0.0275,  ...,  0.0222, -0.0344, -0.0148],\n",
      "        [ 0.0313,  0.0129, -0.0095,  ...,  0.0269, -0.0284, -0.0101],\n",
      "        ...,\n",
      "        [-0.0016,  0.0232,  0.0117,  ..., -0.0331, -0.0169, -0.0142],\n",
      "        [ 0.0302,  0.0312,  0.0284,  ...,  0.0232, -0.0344,  0.0273],\n",
      "        [-0.0071,  0.0146, -0.0291,  ...,  0.0311, -0.0264, -0.0308]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print(\"Updated weights - \", model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we'll put this algorithm into a loop so we can go through all the images. Some nomenclature, one pass through the entire dataset is called an epoch. So here we're going to loop through trainloader to get our training batches. For each batch, we'll doing a training pass where we calculate the loss, do a backwards pass, and update the weights.</p>\n",
    "<br>\n",
    "<b>Excercise</b>\n",
    "<p>Implement the training pass for our network. If you implemented it correctly, you should see the training loss drop with each epoch.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss :  1.799680844934256\n",
      "Training loss :  0.7743649615534841\n",
      "Training loss :  0.4990922042937167\n",
      "Training loss :  0.41980519941620736\n",
      "Training loss :  0.3803307141131684\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "    else:\n",
    "        print(\"Training loss : \",running_loss/len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper2\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, -1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "    \n",
    "ps = torch.exp(logps)\n",
    "helper2.view_classify(img.view(1, 28, 28), ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
